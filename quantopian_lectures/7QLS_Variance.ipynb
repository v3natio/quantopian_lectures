{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 7. QLS - Variance\n",
    "\n",
    "## Measures of Dispersion\n",
    "\n",
    "This measures how spread out a set of data is. This is important because one of the main ways in which risk is measured is in how spread out returns have been historically. If returns have been tight around a value, it's good. If they have been all over the place, it's risky.\n",
    "\n",
    "Data with low dispersion is clustered around the mean, while data with high dispersion indicates many very large/small values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.790905670Z",
     "start_time": "2023-07-26T13:55:15.789717670Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's generate an array of random integers to work with."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [ 3  8 34 39 46 52 52 52 54 57 60 65 66 75 83 85 88 94 95 96]\n",
      "Mean of X: 60.2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(121)\n",
    "\n",
    "# generate 20 random integers < 100\n",
    "X = np.random.randint(100, size=20)\n",
    "\n",
    "# sort them\n",
    "X = np.sort(X)\n",
    "print(\"X:\", X)\n",
    "\n",
    "mu = np.mean(X)\n",
    "print(\"Mean of X:\", mu)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.833541889Z",
     "start_time": "2023-07-26T13:55:15.790198527Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Range\n",
    "\n",
    "It's the difference between the max and min values in a dataset. It's super sensitive to outliers. We use `numpy`'s peak to peak function for this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of X: 93\n"
     ]
    }
   ],
   "source": [
    "print(\"Range of X:\", np.ptp(X))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.834252524Z",
     "start_time": "2023-07-26T13:55:15.833315324Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mean Absolute Deviation (MAD)\n",
    "\n",
    "The mean absolute deviation is the average of the distances of observations from the arithmetic mean. We use the absolute value of the deviation (so that $5$ above and below both contribute $5$) because otherwise it'll always sum to $0$.\n",
    "\n",
    "$$MAD = \\frac{\\sum_{i=1}^{n} \\left| X_{i} - \\mu \\right|}{n}$$\n",
    "\n",
    "Where $n$ is the number of observations and $\\mu$ is their mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Deviation of X: 20.520000000000003\n"
     ]
    }
   ],
   "source": [
    "abs_dispersion = [np.abs(mu - x) for x in X]\n",
    "MAD = np.sum(abs_dispersion)/len(abs_dispersion)\n",
    "print(\"Mean Absolute Deviation of X:\", MAD)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.834877883Z",
     "start_time": "2023-07-26T13:55:15.833769013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variance & Standard Deviation\n",
    "\n",
    "The variance $\\sigma^{2}$ is defined as the average of the squared deviations around the mean:\n",
    "\n",
    "$$\\sigma^{2} = \\frac{\\sum_{i=1}^{n} (X_{i} - \\mu)^{2}}{n}$$\n",
    "\n",
    "This is sometimes more convenient than the mean absolute deviation because squaring is smooth and differentiable.\n",
    "\n",
    "Standard deviation is defined as the square root of the variance $\\sigma$, and it's the easier of the two to interpret because it's in the same units as the observations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of X: 670.16\n",
      "Standard deviation of X: 25.887448696231154\n"
     ]
    }
   ],
   "source": [
    "print(\"Variance of X:\", np.var(X))\n",
    "print(\"Standard deviation of X:\", np.std(X))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.835451490Z",
     "start_time": "2023-07-26T13:55:15.834093984Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One way to interpret standard deviation is by referring to Chebyshev's inequality. This tells us that the proportion of samples within a distance of $k$ standard deviation of the mean is at least $1 - \\frac{1}{k^{2}}$ for all $k > 1$.\n",
    "\n",
    "Let's check that this is true for our data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations within 1.25 stds of mean: [34, 39, 46, 52, 52, 52, 54, 57, 60, 65, 66, 75, 83, 85, 88]\n",
      "Confirming that 0.75 > 0.36\n"
     ]
    }
   ],
   "source": [
    "k = 1.25\n",
    "dist = k*np.std(X)\n",
    "l = [x for x in X if abs(x - mu) <= dist]\n",
    "print(\"Observations within\", k, \"stds of mean:\", l)\n",
    "print(\"Confirming that\", float(len(l))/len(X), '>', 1 - 1/k**2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.835919985Z",
     "start_time": "2023-07-26T13:55:15.834518200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bound given by Chebyshev's inequality seems fairly loose in this case. This bound is rarely strict, but it's useful because it holds for all data sets and distributions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Semivariance & Semideviation\n",
    "\n",
    "Although variance and standard deviation tell us how volatile a quantity is, they don't differentiate between upwards/downwards volatility. With returns on an asset, we're mostly worried about downwards deviation. This is addressed by semivariance and semideviation, which only count the observations that fall below the mean. It's defined as:\n",
    "\n",
    "$$\\frac{\\sum_{X_{i}< \\mu} (X_{i} - \\mu)^{2}}{n_{<}}$$\n",
    "\n",
    "Where $n_{<}$ is the number of observations which are smaller than the mean. Semideviation is the square root of the semivariance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semivariance of X: 689.5127272727273\n",
      "Semideviation of X: 26.258574357202395\n"
     ]
    }
   ],
   "source": [
    "# Because there's no built-in semideviation, we'll compute it ourselves\n",
    "lows = [e for e in X if e <= mu]\n",
    "\n",
    "semivar = np.sum((lows-mu)**2)/len(lows)\n",
    "\n",
    "print(\"Semivariance of X:\", semivar)\n",
    "print(\"Semideviation of X:\", np.sqrt(semivar))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.836318429Z",
     "start_time": "2023-07-26T13:55:15.834767324Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A related notion is target semivariance (and target semideviation), where we average the distance from a target of values which fall below that target:\n",
    "\n",
    "$$\\frac{\\sum_{X_{i}< B} (X_{i} - B)^{2}}{n_{< B}}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target semivariance of X: 188.5\n",
      "Target semideviation of X: 13.729530217745982\n"
     ]
    }
   ],
   "source": [
    "B = 19\n",
    "lows_B = [e for e in X if e <= B]\n",
    "semivar_B = sum(map(lambda x: (x-B)**2,lows_B))/len(lows_B)\n",
    "\n",
    "print(\"Target semivariance of X:\", semivar_B)\n",
    "print(\"Target semideviation of X:\", np.sqrt(semivar_B))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T13:55:15.836675598Z",
     "start_time": "2023-07-26T13:55:15.835118067Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## These are Only Estimates\n",
    "\n",
    "All of these computations will give you sample statistics, that is standard deviation of a sample of data. whether this reflects the current true population standard deviation is not always obvious, and more effort has to be put into determining that. this is especially problematic in finance because all data are time series and the mean and variance may change over time. there are many different techniques and subtleties here.\n",
    "\n",
    "In general do not assume that because something is true of your sample, it will remain true going forward."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
